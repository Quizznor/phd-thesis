{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32m15:43:14\u001b[0m (\u001b[1m\u001b[35m   +3.8s\u001b[0m) \u001b[1m\u001b[32m[INFO   ]\u001b[0m -- import \u001b[1m\u001b[31mlogging\u001b[0m\n",
      "\u001b[1m\u001b[32m15:43:15\u001b[0m (\u001b[1m\u001b[35m  +175ms\u001b[0m) \u001b[1m\u001b[32m[INFO   ]\u001b[0m -- import \u001b[1m\u001b[31mnumpy\u001b[0m as \u001b[1m\u001b[31mnp\u001b[0m\n",
      "\u001b[1m\u001b[32m15:43:15\u001b[0m (\u001b[1m\u001b[35m   +11ms\u001b[0m) \u001b[1m\u001b[32m[INFO   ]\u001b[0m -- import \u001b[1m\u001b[31muncertainties\u001b[0m\n",
      "\u001b[1m\u001b[32m15:43:15\u001b[0m (\u001b[1m\u001b[35m  +400ms\u001b[0m) \u001b[1m\u001b[32m[INFO   ]\u001b[0m -- import \u001b[1m\u001b[31mpandas\u001b[0m as \u001b[1m\u001b[31mpd\u001b[0m\n",
      "\u001b[1m\u001b[33m15:43:15\u001b[0m (\u001b[1m\u001b[35m    +2ms\u001b[0m) \u001b[1m\u001b[33m[WARNING]\u001b[0m -- pandas support to be dropped at some point!\n",
      "\u001b[1m\u001b[32m15:43:15\u001b[0m (\u001b[1m\u001b[35m    +2ms\u001b[0m) \u001b[1m\u001b[32m[INFO   ]\u001b[0m -- import \u001b[1m\u001b[31mbinaries.tools\u001b[0m as \u001b[1m\u001b[31mtools\u001b[0m\n",
      "\u001b[1m\u001b[32m15:43:16\u001b[0m (\u001b[1m\u001b[35m  +960ms\u001b[0m) \u001b[1m\u001b[32m[INFO   ]\u001b[0m -- import \u001b[1m\u001b[31mmatplotlib.pyplot\u001b[0m as \u001b[1m\u001b[31mplt\u001b[0m\n",
      "\u001b[1m\u001b[32m15:43:16\u001b[0m (\u001b[1m\u001b[35m   +40ms\u001b[0m) \u001b[1m\u001b[32m[INFO   ]\u001b[0m -- import \u001b[1m\u001b[31mseaborn\u001b[0m as \u001b[1m\u001b[31mso\u001b[0m\n",
      "\u001b[1m\u001b[32m15:43:16\u001b[0m (\u001b[1m\u001b[35m    +3ms\u001b[0m) \u001b[1m\u001b[32m[INFO   ]\u001b[0m -- import \u001b[1m\u001b[31mplotting.tools\u001b[0m as \u001b[1m\u001b[31mplot\u001b[0m\n",
      "\u001b[1m\u001b[34m15:43:16\u001b[0m (\u001b[1m\u001b[35m   +13ms\u001b[0m) \u001b[1m\u001b[34m[DEBUG  ]\u001b[0m -- font size set to 9.5\n",
      "\u001b[1m\u001b[34m15:43:16\u001b[0m (\u001b[1m\u001b[35m    +1ms\u001b[0m) \u001b[1m\u001b[34m[DEBUG  ]\u001b[0m -- label size set to 13.0\n",
      "\u001b[1m\u001b[34m15:43:16\u001b[0m (\u001b[1m\u001b[35m    +0ms\u001b[0m) \u001b[1m\u001b[34m[DEBUG  ]\u001b[0m -- figure size set to [6.6, 3.3]\n",
      "\u001b[1m\u001b[34m15:43:16\u001b[0m (\u001b[1m\u001b[35m    +1ms\u001b[0m) \u001b[1m\u001b[34m[DEBUG  ]\u001b[0m -- markersize set to 2.0\n",
      "\u001b[1m\u001b[34m15:43:16\u001b[0m (\u001b[1m\u001b[35m    +1ms\u001b[0m) \u001b[1m\u001b[34m[DEBUG  ]\u001b[0m -- usetex set to False\n",
      "\u001b[1m\u001b[32m15:43:16\u001b[0m (\u001b[1m\u001b[35m    +2ms\u001b[0m) \u001b[1m\u001b[32m[INFO   ]\u001b[0m -- set MONI_PATH = '/cr/work/filip/monit_and_sd/'\n",
      "\u001b[1m\u001b[32m15:43:16\u001b[0m (\u001b[1m\u001b[35m    +1ms\u001b[0m) \u001b[1m\u001b[32m[INFO   ]\u001b[0m -- set HIST_PATH = '/cr/work/filip/monit_and_sd/'\n",
      "\u001b[1m\u001b[32m15:43:16\u001b[0m (\u001b[1m\u001b[35m    +0ms\u001b[0m) \u001b[1m\u001b[32m[INFO   ]\u001b[0m -- set PLOT_PATH = '/cr/data01/filip/plots/'\n",
      "\u001b[1m\u001b[32m15:43:16\u001b[0m (\u001b[1m\u001b[35m    +1ms\u001b[0m) \u001b[1m\u001b[32m[INFO   ]\u001b[0m -- set DATA_PATH = '/cr/data01/filip/Data/'\n"
     ]
    }
   ],
   "source": [
    "from utils.Auger.SD.UubRandoms import UubRandom\n",
    "from utils.binaries import *\n",
    "\n",
    "class BackgroundStudy():\n",
    "\n",
    "    def __init__(self, fctn: callable):\n",
    "\n",
    "        time_passed, triggers = 0, 0\n",
    "        RandomFiles = UubRandom(station = \"Svenja\", detectors = \"ssd\")\n",
    "    \n",
    "        self.trigger_examples = []\n",
    "        for File in tools.ProgressBar(RandomFiles, newline=False):\n",
    "            for event in File:\n",
    "\n",
    "                calibrated = event['trace'] / event['mip_peak']\n",
    "                time_passed += 2048 * 8.33e-9                       # add time\n",
    "\n",
    "                if fctn(calibrated):                                # add trigger\n",
    "                    self.trigger_examples.append(event)\n",
    "                    triggers += 1\n",
    "            \n",
    "            rate = uncertainties.ufloat(triggers, np.sqrt(triggers)) / time_passed\n",
    "            if rate.n > 10: print(f\"\\n   Rate after {time_passed:.3f}s = ({rate}) Hz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numba\n",
    "\n",
    "@numba.jit\n",
    "def trigger_example(trace):\n",
    "    for _bin in trace:\n",
    "        if _bin > 3.2: return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/800 [                    ] || 00:00:00>00:00:00,    243013.37 it/s\n",
      "   Rate after 0.085s = (82+/-31) Hz\n",
      "  2/800 [                    ] || 00:00:01>00:10:28,         1.27 it/s\n",
      "   Rate after 0.171s = (41+/-16) Hz\n",
      "  3/800 [                    ] || 00:00:02>00:11:03,         1.20 it/s\n",
      "   Rate after 0.256s = (39+/-12) Hz\n",
      "  4/800 [                    ] || 00:00:03>00:11:21,         1.17 it/s\n",
      "   Rate after 0.341s = (41+/-11) Hz\n",
      "  5/800 [                    ] || 00:00:04>00:11:31,         1.15 it/s\n",
      "   Rate after 0.426s = (38+/-9) Hz\n",
      "  6/800 [                    ] || 00:00:05>00:11:38,         1.14 it/s\n",
      "   Rate after 0.512s = (39+/-9) Hz\n",
      "  7/800 [                    ] || 00:00:06>00:11:40,         1.13 it/s\n",
      "   Rate after 0.597s = (35+/-8) Hz\n",
      "  8/800 [                    ] || 00:00:07>00:11:40,         1.13 it/s\n",
      "   Rate after 0.682s = (34+/-7) Hz\n",
      "  9/800 [                    ] || 00:00:07>00:11:40,         1.13 it/s\n",
      "   Rate after 0.768s = (31+/-6) Hz\n",
      " 10/800 [                    ] || 00:00:08>00:11:40,         1.13 it/s\n",
      "   Rate after 0.853s = (32+/-6) Hz\n",
      " 11/800 [                    ] || 00:00:09>00:11:41,         1.13 it/s\n",
      "   Rate after 0.938s = (31+/-6) Hz\n",
      " 12/800 [                    ] || 00:00:10>00:11:40,         1.12 it/s\n",
      "   Rate after 1.024s = (28+/-5) Hz\n",
      " 13/800 [                    ] || 00:00:11>00:11:40,         1.12 it/s\n",
      "   Rate after 1.109s = (28+/-5) Hz\n",
      " 14/800 [                    ] || 00:00:12>00:11:39,         1.12 it/s\n",
      "   Rate after 1.194s = (28+/-5) Hz\n",
      " 15/800 [                    ] || 00:00:13>00:11:38,         1.12 it/s\n",
      "   Rate after 1.279s = (27+/-5) Hz\n",
      " 16/800 [                    ] || 00:00:14>00:11:40,         1.12 it/s\n",
      "   Rate after 1.365s = (28+/-5) Hz\n",
      " 17/800 [                    ] || 00:00:15>00:11:43,         1.11 it/s\n",
      "   Rate after 1.450s = (29+/-4) Hz\n",
      " 18/800 [                    ] || 00:00:16>00:11:45,         1.11 it/s\n",
      "   Rate after 1.535s = (28+/-4) Hz\n",
      " 19/800 [                    ] || 00:00:17>00:11:44,         1.11 it/s\n",
      "   Rate after 1.621s = (28+/-4) Hz\n",
      " 20/800 [                    ] || 00:00:18>00:11:44,         1.11 it/s\n",
      "   Rate after 1.706s = (28+/-4) Hz\n",
      " 21/800 [                    ] || 00:00:18>00:11:44,         1.11 it/s\n",
      "   Rate after 1.791s = (27+/-4) Hz\n",
      " 22/800 [                    ] || 00:00:19>00:11:42,         1.11 it/s\n",
      "   Rate after 1.877s = (27+/-4) Hz\n",
      " 23/800 [                    ] || 00:00:20>00:11:41,         1.11 it/s\n",
      "   Rate after 1.877s = (27+/-4) Hz\n",
      " 24/800 [                    ] || 00:00:20>00:11:11,         1.16 it/s\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m test \u001b[38;5;241m=\u001b[39m \u001b[43mBackgroundStudy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrigger_example\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 12\u001b[0m, in \u001b[0;36mBackgroundStudy.__init__\u001b[0;34m(self, fctn)\u001b[0m\n\u001b[1;32m      9\u001b[0m RandomFiles \u001b[38;5;241m=\u001b[39m UubRandom(station \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSvenja\u001b[39m\u001b[38;5;124m\"\u001b[39m, detectors \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mssd\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrigger_examples \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m File \u001b[38;5;129;01min\u001b[39;00m tools\u001b[38;5;241m.\u001b[39mProgressBar(RandomFiles, newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m File:\n\u001b[1;32m     15\u001b[0m         calibrated \u001b[38;5;241m=\u001b[39m event[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrace\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m/\u001b[39m event[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmip_peak\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/bin/utils/binaries/binary_tools.py:58\u001b[0m, in \u001b[0;36mProgressBar.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__index \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlen:\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28mprint\u001b[39m()\n\u001b[0;32m---> 58\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/bin/utils/Auger/SD/UubRandoms.py:64\u001b[0m, in \u001b[0;36mUubRandom.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__index \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__len__\u001b[39m():\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n\u001b[0;32m---> 64\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__index \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/bin/utils/Auger/SD/UubRandoms.py:73\u001b[0m, in \u001b[0;36mUubRandom.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index: \u001b[38;5;28mint\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m TUPLE_OR_ARRAY:\n\u001b[0;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/bin/utils/Auger/SD/UubRandoms.py:80\u001b[0m, in \u001b[0;36mUubRandom.read\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ext \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mextensions:\n\u001b[1;32m     79\u001b[0m     file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/randoms\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mindex\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m04\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.bz2\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 80\u001b[0m     buffer \u001b[38;5;241m=\u001b[39m \u001b[43mbz2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBZ2File\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m     results\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39mfrombuffer(buffer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt[ext]))\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(results) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m results[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/usr/lib/python3.10/bz2.py:164\u001b[0m, in \u001b[0;36mBZ2File.read\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Read up to size uncompressed bytes from the file.\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \n\u001b[1;32m    160\u001b[0m \u001b[38;5;124;03mIf size is negative or omitted, read until EOF is reached.\u001b[39;00m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;124;03mReturns b'' if the file is already at EOF.\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_can_read()\n\u001b[0;32m--> 164\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_buffer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.10/_compression.py:118\u001b[0m, in \u001b[0;36mDecompressReader.readall\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    114\u001b[0m chunks \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    115\u001b[0m \u001b[38;5;66;03m# sys.maxsize means the max length of output buffer is unlimited,\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;66;03m# so that the whole input buffer can be decompressed within one\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;66;03m# .decompress() call.\u001b[39;00m\n\u001b[0;32m--> 118\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m data \u001b[38;5;241m:=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaxsize\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    119\u001b[0m     chunks\u001b[38;5;241m.\u001b[39mappend(data)\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(chunks)\n",
      "File \u001b[0;32m/usr/lib/python3.10/_compression.py:103\u001b[0m, in \u001b[0;36mDecompressReader.read\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    102\u001b[0m         rawblock \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 103\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_decompressor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecompress\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrawblock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data:\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test = BackgroundStudy(trigger_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.CONSTANTS import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.binaries import *\n",
    "from utils.plotting import *\n",
    "\n",
    "peaks = np.loadtxt(\n",
    "    \"/cr/data01/filip/Data/daqIntegrationTests/v42/peak.txt\", usecols=range(3, 153)\n",
    ")\n",
    "charges = np.loadtxt(\n",
    "    \"/cr/data01/filip/Data/daqIntegrationTests/v42/charge.txt\", usecols=range(3, 603)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peaks = np.split(peaks, len(peaks) / 4)\n",
    "charges = np.split(charges, len(charges) / 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import argrelextrema\n",
    "from scipy.optimize import curve_fit\n",
    "from itertools import product\n",
    "from utils import CONSTANTS\n",
    "\n",
    "\n",
    "class SdHisto:\n",
    "    def __init__(\n",
    "        self, *, peak: list[np.ndarray] = None, charge: list[np.ndarray] = None\n",
    "    ) -> None:\n",
    "\n",
    "        assert peak is None or len(peak) == 4, \"Missing a PMT?\"\n",
    "        assert charge is None or len(charge) == 4, \"Missing a PMT?\"\n",
    "\n",
    "        self.histos = {\"peak\": peak, \"charge\": charge}\n",
    "        self.popts = {\n",
    "            \"peak\": [[np.nan, np.nan] for _ in range(4)],\n",
    "            \"charge\": [[np.nan, np.nan] for _ in range(4)],\n",
    "        }\n",
    "\n",
    "    def fit(self, correlate: bool = True) -> dict:\n",
    "\n",
    "        if self.histos[\"peak\"] is not None:\n",
    "            self.popts[\"peak\"] = self.get_peak(\"peak\", correlate)\n",
    "        if self.histos[\"charge\"] is not None:\n",
    "            self.popts[\"charge\"] = self.get_peak(\"charge\", correlate)\n",
    "\n",
    "        return self.popts\n",
    "\n",
    "    def get_peak(self, mode: str, correlate: bool) -> list[list[uncertainties.ufloat]]:\n",
    "\n",
    "        peaks = []\n",
    "        for i, counts in enumerate(self.histos[mode]):\n",
    "\n",
    "            if i < 3:\n",
    "                peaks.append(\n",
    "                    self.fit_wcd(counts[: (99 if mode == \"peak\" else 399)], correlate)\n",
    "                )\n",
    "            else:\n",
    "                peaks.append(\n",
    "                    self.fit_ssd(counts[: (99 if mode == \"peak\" else 399)], correlate)\n",
    "                )\n",
    "\n",
    "        return peaks\n",
    "\n",
    "    @staticmethod\n",
    "    def fit_wcd(counts: np.ndarray, correlate: bool) -> list[uncertainties.ufloat]:\n",
    "\n",
    "        try:\n",
    "            match len(counts):\n",
    "                case 99:\n",
    "                    increment = 5\n",
    "                    bins = CONSTANTS.UUB_WCD_PEAK\n",
    "                    initial_start = 99 - increment\n",
    "                case 399:\n",
    "                    increment = 20\n",
    "                    bins = CONSTANTS.UUB_WCD_CHARGE\n",
    "                    initial_start = 399 - increment\n",
    "                case _:\n",
    "                    raise IndexError(f\"received histogram with length {len(counts)}\")\n",
    "\n",
    "            old_peak, guess = np.argmax(counts[initial_start:]), 0\n",
    "            while old_peak != guess:\n",
    "                old_peak = guess\n",
    "                initial_start -= increment\n",
    "                guess = np.argmax(counts[initial_start:]) + initial_start\n",
    "\n",
    "            start, stop = guess - increment, guess + increment\n",
    "            x1, x2, y1, y2 = (\n",
    "                start,\n",
    "                len(counts) - 1,\n",
    "                counts[stop],\n",
    "                counts[len(counts) - 1],\n",
    "            )\n",
    "            background_slope = lambda x: (y2 - y1) / (x2 - x1) * (x - x1) + y1\n",
    "\n",
    "            popts, pcov = curve_fit(\n",
    "                SdHisto.parabola,\n",
    "                bins[start:stop],\n",
    "                np.log(counts[start:stop])\n",
    "                - background_slope(np.arange(start, stop, 1)),\n",
    "                bounds=([-np.inf, 0, 0], [0, np.inf, np.inf]),\n",
    "                maxfev=100000,\n",
    "                p0=[-0.01, bins[guess], counts[guess]],\n",
    "                nan_policy=\"omit\",\n",
    "            )\n",
    "\n",
    "            if correlate:\n",
    "                popts = uncertainties.correlated_values(popts, pcov)\n",
    "                # if len(counts) == 99 and popts[1].n < 100 or 300 < popts[1].n: raise ValueError(f\"calculated {popts[1]:i} ADC for WCD peak\")\n",
    "                # if len(counts) == 399 and popts[1].n < 1000 or 2000 < popts[1].n: raise ValueError(f\"calculated {popts[1]:i} ADC for WCD charge\")\n",
    "                if (r := popts[1].std_dev / popts[1].n) > 0.2:\n",
    "                    raise ValueError(f\"large fit error for WCD: {r*100:.0f}%\")\n",
    "\n",
    "                return popts\n",
    "\n",
    "        except ValueError as e:\n",
    "            print(f\"WCD SdHisto fit failed: {e}\")\n",
    "            return [uncertainties.ufloat(np.nan, np.nan) for _ in range(3)]\n",
    "\n",
    "    @staticmethod\n",
    "    def fit_ssd(counts: np.ndarray, correlate: bool) -> list[uncertainties.ufloat]:\n",
    "\n",
    "        try:\n",
    "            match len(counts):\n",
    "                case 99:\n",
    "                    bins = CONSTANTS.UUB_SSD_PEAK\n",
    "                    increment = 5\n",
    "                    start = np.argmax(counts)\n",
    "\n",
    "                    while not np.argmax(counts[start:]):\n",
    "                        start += 1\n",
    "                case 399:\n",
    "                    bins = CONSTANTS.UUB_SSD_CHARGE\n",
    "                    increment = 20\n",
    "                    order = 10\n",
    "\n",
    "                    while (\n",
    "                        len(\n",
    "                            (dips := argrelextrema(counts[1:], np.less, order=order)[0])\n",
    "                        )\n",
    "                        > 1\n",
    "                    ):\n",
    "                        order += 1\n",
    "                    start = dips[0] + 1\n",
    "\n",
    "                case _:\n",
    "                    raise IndexError(f\"received histogram with length {len(counts)}\")\n",
    "\n",
    "            guess = start + np.argmax(counts[start:])\n",
    "            start, stop = guess - increment, guess + increment\n",
    "\n",
    "            popts, pcov = curve_fit(\n",
    "                SdHisto.parabola,\n",
    "                bins[start:stop],\n",
    "                counts[start:stop],\n",
    "                bounds=([-np.inf, 0, 0], [0, np.inf, np.inf]),\n",
    "                maxfev=100000,\n",
    "                p0=[-0.01, bins[guess], counts[guess]],\n",
    "                nan_policy=\"omit\",\n",
    "            )\n",
    "\n",
    "            if correlate:\n",
    "                popts = uncertainties.correlated_values(popts, pcov)\n",
    "                # if len(counts) == 99 and popts[1].n < 20 or 100 < popts[1].n: raise ValueError(f\"calculated {popts[1]:i} ADC for SSD peak\")\n",
    "                # if len(counts) == 399 and popts[1].n < 20 or 100 < popts[1].n: raise ValueError(f\"calculated {popts[1]:i} ADC for SSD charge\")\n",
    "                if (r := popts[1].std_dev / popts[1].n) > 0.2:\n",
    "                    raise ValueError(f\"large fit error for SSD: {r*100:.0f}%\")\n",
    "\n",
    "                return popts\n",
    "\n",
    "        except ValueError as e:\n",
    "            print(f\"SSD SdHisto fit failed: {e}\")\n",
    "            return [uncertainties.ufloat(np.nan, np.nan) for _ in range(4)]\n",
    "\n",
    "    def plot(self) -> plt.Figure:\n",
    "\n",
    "        if self.histos[\"peak\"] is not None and self.histos[\"charge\"] is not None:\n",
    "            fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "        else:\n",
    "            fig, ax = plt.subplots()\n",
    "            ax1 = ax2 = ax\n",
    "\n",
    "        f = 4\n",
    "        c = [\"red\", \"blue\", \"mediumturquoise\", \"k\"]\n",
    "        l = [\"WCD1\", \"WCD2\", \"WCD3\", rf\"SSD $\\times$ {f}\"]\n",
    "\n",
    "        if self.histos[\"peak\"] is not None:\n",
    "            ax1.set_xlabel(\"max. pulse height / ADC\")\n",
    "            for i, counts in enumerate(self.histos[\"peak\"]):\n",
    "                factor = 1 if i < 3 else f\n",
    "                ax1.plot(\n",
    "                    self.get_bins(\"peak\", i) * factor,\n",
    "                    counts,\n",
    "                    c=c[i],\n",
    "                    ls=\"-\",\n",
    "                    label=l[i],\n",
    "                )\n",
    "                ax1.axvline(\n",
    "                    self.popts[\"peak\"][i][1].n * factor, lw=0.4, ls=\"--\", c=c[i]\n",
    "                )\n",
    "                err = (\n",
    "                    self.popts[\"peak\"][i][1].std_dev * np.array([-1, 1])\n",
    "                    + self.popts[\"peak\"][i][1].n\n",
    "                )\n",
    "                ax1.axvspan(*(err * factor), color=c[i], alpha=0.1)\n",
    "\n",
    "            ax1.set_xlim(0, 400)\n",
    "            ax1.legend(title=\"Peak\")\n",
    "\n",
    "        if self.histos[\"charge\"] is not None:\n",
    "            ax2.set_xlabel(\"integral / ADC\")\n",
    "            for i, counts in enumerate(self.histos[\"charge\"]):\n",
    "                factor = 1 if i < 3 else f\n",
    "                ax2.plot(\n",
    "                    self.get_bins(\"charge\", i) * factor,\n",
    "                    counts,\n",
    "                    c=c[i],\n",
    "                    ls=\"-\",\n",
    "                    label=l[i],\n",
    "                )\n",
    "                ax2.axvline(\n",
    "                    self.popts[\"charge\"][i][1].n * factor, lw=0.4, ls=\"--\", c=c[i]\n",
    "                )\n",
    "                err = (\n",
    "                    self.popts[\"charge\"][i][1].std_dev * np.array([-1, 1])\n",
    "                    + self.popts[\"charge\"][i][1].n\n",
    "                )\n",
    "                ax2.axvspan(*(err * factor), color=c[i], alpha=0.1)\n",
    "\n",
    "            ax2.set_xlim(0, 3200)\n",
    "            ax2.legend(title=\"Charge\")\n",
    "\n",
    "        return fig\n",
    "\n",
    "    @staticmethod\n",
    "    def parabola(x, scale, mip, y0):\n",
    "        return scale * (x - mip) ** 2 + y0\n",
    "\n",
    "    @staticmethod\n",
    "    def get_bins(mode: str, pmt: int) -> np.ndarray:\n",
    "\n",
    "        if mode == \"peak\" and pmt < 3:\n",
    "            return CONSTANTS.UUB_WCD_PEAK\n",
    "        elif mode == \"peak\" and pmt == 3:\n",
    "            return CONSTANTS.UUB_SSD_PEAK\n",
    "        elif mode == \"charge\" and pmt < 3:\n",
    "            return CONSTANTS.UUB_WCD_CHARGE\n",
    "        elif mode == \"charge\" and pmt == 3:\n",
    "            return CONSTANTS.UUB_SSD_CHARGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (p, c) in enumerate(zip(peaks, charges)):\n",
    "    histo = SdHisto(peak=p, charge=c)\n",
    "    histo.fit()\n",
    "    histo.plot()\n",
    "\n",
    "    if i > 0:\n",
    "        break\n",
    "\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\n",
    "    f\"/cr/data01/filip/xy-calibration/results/outPositionsComb_12809.txt\",\n",
    "    sep=\",\",\n",
    "    names=(\n",
    "        \"time\",\n",
    "        \"x\",\n",
    "        \"y\",\n",
    "        \"event_number\",\n",
    "        \"user_id\",\n",
    "        \"temp_led\",\n",
    "        \"temp_phd\",\n",
    "        \"temp_board\",\n",
    "        \"phd_signal\",\n",
    "        \"FDeventSum\",\n",
    "    ),\n",
    "    comment=\"#\",\n",
    "    header=0,\n",
    ")\n",
    "\n",
    "\n",
    "df[\"r\"] = np.sqrt(df[\"x\"] ** 2 + df[\"y\"] ** 2)\n",
    "df[\"f\"] = df[\"FDeventSum\"] / df[\"FDeventSum\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "_ = plt.hist(df[\"f\"], histtype=\"step\", bins=100)\n",
    "# plt.xlim(0, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "df[\"r\"] = np.sqrt(df[\"x\"] ** 2 + df[\"y\"] ** 2)\n",
    "\n",
    "df_select = df[(df[\"f\"].between(0, 0.1)) & (df[\"r\"] > 850)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df_select[\"x\"], df_select[\"y\"], s=10)\n",
    "aperture = plt.Circle(\n",
    "    (0, 0), 1100, color=\"tab:red\", fill=False, lw=2, zorder=0, alpha=0.5\n",
    ")\n",
    "\n",
    "plt.gca().add_artist(aperture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_select[\"r\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
