{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[5m\u001b[1m\u001b[32m14:56:31\u001b[0m (\u001b[1m\u001b[35m   +9.0s\u001b[0m) \u001b[5m\u001b[1m\u001b[32m[INFO   ]\u001b[0m -- import \u001b[5m\u001b[1m\u001b[31mlogging\u001b[0m\n",
      "\u001b[5m\u001b[1m\u001b[32m14:56:31\u001b[0m (\u001b[1m\u001b[35m  +160ms\u001b[0m) \u001b[5m\u001b[1m\u001b[32m[INFO   ]\u001b[0m -- import \u001b[5m\u001b[1m\u001b[31mnumpy\u001b[0m as \u001b[5m\u001b[1m\u001b[31mnp\u001b[0m\n",
      "\u001b[5m\u001b[1m\u001b[32m14:56:31\u001b[0m (\u001b[1m\u001b[35m    +7ms\u001b[0m) \u001b[5m\u001b[1m\u001b[32m[INFO   ]\u001b[0m -- import \u001b[5m\u001b[1m\u001b[31muncertainties\u001b[0m\n",
      "\u001b[5m\u001b[1m\u001b[32m14:56:31\u001b[0m (\u001b[1m\u001b[35m  +208ms\u001b[0m) \u001b[5m\u001b[1m\u001b[32m[INFO   ]\u001b[0m -- import \u001b[5m\u001b[1m\u001b[31mpandas\u001b[0m as \u001b[5m\u001b[1m\u001b[31mpd\u001b[0m\n",
      "\u001b[5m\u001b[1m\u001b[33m14:56:31\u001b[0m (\u001b[1m\u001b[35m    +2ms\u001b[0m) \u001b[5m\u001b[1m\u001b[33m[WARNING]\u001b[0m -- pandas support to be dropped at some point!\n",
      "\u001b[5m\u001b[1m\u001b[32m14:56:31\u001b[0m (\u001b[1m\u001b[35m    +1ms\u001b[0m) \u001b[5m\u001b[1m\u001b[32m[INFO   ]\u001b[0m -- import \u001b[5m\u001b[1m\u001b[31mbinaries.tools\u001b[0m as \u001b[5m\u001b[1m\u001b[31mtools\u001b[0m\n",
      "\u001b[5m\u001b[1m\u001b[32m14:56:31\u001b[0m (\u001b[1m\u001b[35m  +285ms\u001b[0m) \u001b[5m\u001b[1m\u001b[32m[INFO   ]\u001b[0m -- import \u001b[5m\u001b[1m\u001b[31mmatplotlib.pyplot\u001b[0m as \u001b[5m\u001b[1m\u001b[31mplt\u001b[0m\n",
      "\u001b[5m\u001b[1m\u001b[32m14:56:32\u001b[0m (\u001b[1m\u001b[35m  +430ms\u001b[0m) \u001b[5m\u001b[1m\u001b[32m[INFO   ]\u001b[0m -- import \u001b[5m\u001b[1m\u001b[31mseaborn\u001b[0m as \u001b[5m\u001b[1m\u001b[31mso\u001b[0m\n",
      "\u001b[5m\u001b[1m\u001b[34m14:56:32\u001b[0m (\u001b[1m\u001b[35m    +6ms\u001b[0m) \u001b[5m\u001b[1m\u001b[34m[DEBUG  ]\u001b[0m -- font size set to 9.5\n",
      "\u001b[5m\u001b[1m\u001b[34m14:56:32\u001b[0m (\u001b[1m\u001b[35m    +2ms\u001b[0m) \u001b[5m\u001b[1m\u001b[34m[DEBUG  ]\u001b[0m -- label size set to 13.0\n",
      "\u001b[5m\u001b[1m\u001b[34m14:56:32\u001b[0m (\u001b[1m\u001b[35m    +0ms\u001b[0m) \u001b[5m\u001b[1m\u001b[34m[DEBUG  ]\u001b[0m -- figure size set to [6.6, 3.3]\n",
      "\u001b[5m\u001b[1m\u001b[34m14:56:32\u001b[0m (\u001b[1m\u001b[35m    +1ms\u001b[0m) \u001b[5m\u001b[1m\u001b[34m[DEBUG  ]\u001b[0m -- markersize set to 2.0\n",
      "\u001b[5m\u001b[1m\u001b[34m14:56:32\u001b[0m (\u001b[1m\u001b[35m    +1ms\u001b[0m) \u001b[5m\u001b[1m\u001b[34m[DEBUG  ]\u001b[0m -- usetex set to False\n",
      "\u001b[5m\u001b[1m\u001b[32m14:56:32\u001b[0m (\u001b[1m\u001b[35m    +2ms\u001b[0m) \u001b[5m\u001b[1m\u001b[32m[INFO   ]\u001b[0m -- import \u001b[5m\u001b[1m\u001b[31mplotting.tools\u001b[0m as \u001b[5m\u001b[1m\u001b[31mplot\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from utils.binaries import *\n",
    "from utils.plotting import *\n",
    "import pickle\n",
    "\n",
    "import polars as pl\n",
    "\n",
    "from utils.Auger.SD.Triggers import filter_and_downsample, wcd_t1_trigger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(path_to_file):\n",
    "\n",
    "    trace_has_ssd = lambda df: len(df.filter(pl.col(\"id\") == 5)) == 1\n",
    "    trace_has_all_wcd = (\n",
    "        lambda df: len(\n",
    "            df.filter(\n",
    "                (pl.col(\"pmt\") == 1) | (pl.col(\"pmt\") == 2) | (pl.col(\"pmt\") == 3)\n",
    "            )\n",
    "        )\n",
    "        == 3\n",
    "    )\n",
    "\n",
    "    data = pl.read_csv(\n",
    "        path_to_file,\n",
    "        has_header=False,\n",
    "        skip_rows=1,\n",
    "        new_columns=[\"id\", \"pmt\", \"baseline\"],\n",
    "    )\n",
    "\n",
    "    data = data.with_columns(\n",
    "        zero_trace=pl.concat_list(\n",
    "            pl.exclude(\"id\", \"pmt\", \"baseline\") - pl.col(\"baseline\")\n",
    "        )\n",
    "    )\n",
    "    data = data.select(\"id\", \"pmt\", \"baseline\", \"zero_trace\")\n",
    "\n",
    "    for _id, pmt, baseline, trace in data.iter_rows():\n",
    "        if sum([_bin is None for _bin in trace]):\n",
    "            data = data.filter(pl.col(\"id\") != _id)\n",
    "\n",
    "    return data.group_by([\"id\"])\n",
    "\n",
    "\n",
    "def clip_zero_signal(trace):\n",
    "\n",
    "    pmt1, pmt2, pmt3 = trace\n",
    "    assert (\n",
    "        (trace_length := len(pmt1)) == len(pmt2) == len(pmt3)\n",
    "    ), \"Unrealistic time trace\"\n",
    "\n",
    "    for start in range(trace_length):\n",
    "        if pmt1[start] != pmt2[start] != pmt3[start] != 0:\n",
    "            break\n",
    "    for stop in range(-1, -trace_length, -1):\n",
    "        if pmt1[stop] != pmt2[stop] != pmt3[stop] != 0:\n",
    "            break\n",
    "\n",
    "    return np.array(trace)[:, max(start - 10, 0) : min(stop + 10, trace_length)]\n",
    "\n",
    "\n",
    "def plot_test_trace(trace, ax):\n",
    "    pmt1, pmt2, pmt3 = trace\n",
    "    ax.plot(range(len(pmt1)), pmt1, label=\"pmt1\")\n",
    "    ax.plot(range(len(pmt1)), pmt2, label=\"pmt2\")\n",
    "    ax.plot(range(len(pmt1)), pmt3, label=\"pmt3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "528/528\r"
     ]
    }
   ],
   "source": [
    "# from /cr/data01/filip/offline/Framework/SDetector/SdSimCalibrationConstants.xml.in\n",
    "vem_peak = np.array([215.781, 215.781, 215.781])\n",
    "mip_peak = 51.8\n",
    "\n",
    "trace_has_all_wcd = lambda df: len(get_wcd_traces(df)) == 3\n",
    "\n",
    "get_wcd_traces = lambda df: df.filter(\n",
    "    (pl.col(\"pmt\") == 1) | (pl.col(\"pmt\") == 2) | (pl.col(\"pmt\") == 3)\n",
    ").to_numpy()[:, 3:][:, 0]\n",
    "\n",
    "read_file = lambda path: pl.read_csv(\n",
    "    path,\n",
    "    has_header=False,\n",
    "    skip_rows=1,\n",
    "    new_columns=[\"id\", \"pmt\", \"baseline\"],\n",
    ")\n",
    "\n",
    "import os\n",
    "\n",
    "run = \"run4\"\n",
    "base = f\"/cr/tempdata01/filip/LESimulations/{run}\"\n",
    "for step, file in enumerate(os.listdir(base), 1):\n",
    "\n",
    "    if not file.startswith(\"x\"):\n",
    "        continue\n",
    "\n",
    "    print(f\"{step}/{len(os.listdir(base))}\", end=\"\\r\")\n",
    "    # if step >= 10: break\n",
    "\n",
    "    data = read_file(f\"{base}/{file}\")\n",
    "    data = data.with_columns(\n",
    "        zero_trace=pl.concat_list(\n",
    "            pl.exclude(\"id\", \"pmt\", \"baseline\") - pl.col(\"baseline\")\n",
    "        )\n",
    "    )\n",
    "    data = data.select(\"id\", \"pmt\", \"baseline\", \"zero_trace\")\n",
    "\n",
    "    for _id, pmt, baseline, trace in data.iter_rows():\n",
    "        if sum([_bin is None for _bin in trace]):\n",
    "            data = data.filter(pl.col(\"id\") != _id)\n",
    "\n",
    "    data.rechunk()\n",
    "\n",
    "    events = data[\"id\"].unique()\n",
    "    traces = data.group_by([\"id\"])\n",
    "\n",
    "    t1_peaks, all_peaks = [], []\n",
    "    for _id, trace in traces:\n",
    "        if len(trace.filter(pl.col(\"pmt\") == 5)) == 0:\n",
    "            continue  # no signal in SSD\n",
    "\n",
    "        if not trace_has_all_wcd(trace):\n",
    "            t1_latch_bin = -1  # not all WCD PMTs received signal -> no T1\n",
    "        else:\n",
    "            wcd_traces = get_wcd_traces(trace)\n",
    "            filtered_downsampled = filter_and_downsample(*wcd_traces)\n",
    "            # fds_clipped_trace = clip_zero_signal(filtered_downsampled)\n",
    "            vem_trace = np.array(filtered_downsampled) / vem_peak[:, np.newaxis]\n",
    "\n",
    "            t1_latch_bin = wcd_t1_trigger(vem_trace, latch_bin=True)\n",
    "\n",
    "        ssd_trace = (\n",
    "            trace.filter(pl.col(\"pmt\") == 5)[\"zero_trace\"].to_numpy()[0] / mip_peak\n",
    "        )\n",
    "\n",
    "        if t1_latch_bin != -1:\n",
    "            t1_latch_bin *= 3  # to convert from UUB to UB binning\n",
    "            ssd_max = ssd_trace[\n",
    "                max(0, t1_latch_bin - 19) : min(t1_latch_bin + 40, len(ssd_trace))\n",
    "            ].max()\n",
    "            t1_peaks.append(ssd_max)\n",
    "        else:\n",
    "            ssd_max = ssd_trace.max()\n",
    "\n",
    "        all_peaks.append(ssd_max)\n",
    "\n",
    "    with open(\n",
    "        f\"/cr/tempdata01/filip/LESimulations/processed/{run}_{file}_all.pkl\", \"wb\"\n",
    "    ) as f:\n",
    "        pickle.dump(all_peaks, f)\n",
    "    with open(\n",
    "        f\"/cr/tempdata01/filip/LESimulations/processed/{run}_{file}_t1.pkl\", \"wb\"\n",
    "    ) as f:\n",
    "        pickle.dump(t1_peaks, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2, 1)\n",
    "\n",
    "plot_test_trace(np.array(wcd_traces) / vem_peak[:, np.newaxis], ax1)\n",
    "# plot_test_trace(vem_trace, ax2)\n",
    "# ax2.plot(range(len(ssd_trace) // 3), ssd_trace[::3])\n",
    "ax1.plot(range(len(ssd_trace)), np.array(ssd_trace))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
