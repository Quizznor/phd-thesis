{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4dcbdde3-fd95-418e-9fe3-e6146c07a971",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mF\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "# Standard library imports\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "from pprint import pprint\n",
    "\n",
    "# Third party imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1.inset_locator import Bbox, inset_axes\n",
    "from scipy.special import expit\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    roc_curve,\n",
    ")\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import random_split\n",
    "from torch_geometric.data import Dataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_sparse import coalesce\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Local application imports\n",
    "sys.path.append(\"/pbs/home/e/erodrigu/TesisPhDEzequielRodriguez/Code\")\n",
    "from my_utils.gnn_dataset_utilities import (\n",
    "    MaskNode,\n",
    "    PruneGraph2FirstCrown,\n",
    "    SD433UMDatasetPyG,\n",
    "    get_station_features,\n",
    "    plot_graph\n",
    ")\n",
    "from my_utils.my_basic_utils import (\n",
    "    add_zenith_related_columns,\n",
    "    create_bins,\n",
    "    filter_dataframe,\n",
    "    print_banner_text,\n",
    ")\n",
    "from my_utils.my_style import MyStyle\n",
    "from my_utils.torch_models_and_utilities import (\n",
    "    FocalLoss,\n",
    "    GNNDiscriminator,\n",
    "    ROC_resam,\n",
    "    TraceAnalyzer,\n",
    "    evaluate_model_to_dataframe,\n",
    "    get_accuracy,\n",
    ")\n",
    "\n",
    "# set PATHS\n",
    "code_PATH = os.path.abspath(os.path.join(\"..\"))\n",
    "project_PATH = os.path.abspath(os.path.join(code_PATH, \"..\"))\n",
    "data_PATH = os.path.join(project_PATH, \"data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c16d5d-1cbe-4f9a-820c-796f57e1836f",
   "metadata": {},
   "source": [
    "### Version check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b853d48-df9e-4535-a19d-c6475914bf49",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Torch version: {torch.__version__}\")\n",
    "print(f\"Torch CUDA version: {torch.version.cuda}\")\n",
    "print(f\"Cuda available: {torch.cuda.is_available()}\")\n",
    "print(f\"Torch geometric version: {torch_geometric.__version__}\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device is: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57db72b-3463-4b0b-bd17-b38717a3392d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c937bbaa-ef0b-4164-b3b1-60b6eaf5689e",
   "metadata": {},
   "source": [
    "### Dataset Index Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbaae67-c649-431d-a9f5-348b4070f51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"/sps/pauger/users/erodriguez/PhotonDiscrimination/\"\n",
    "dir_path = \"/sps/pauger/users/erodriguez/PhotonDiscrimination/JSONfiles/\"\n",
    "index = pd.DataFrame()\n",
    "\n",
    "# indexes\n",
    "primaries = [\"Proton\", \"Photon\"]\n",
    "energy_bins = [\"16.5_17.0\", \"17.0_17.5\"]\n",
    "atms = [\"01\", \"03\", \"08\", \"09\"]\n",
    "indexes = [\n",
    "    f\"index_hadron_rec_{x}_{y}_{z}.csv\"\n",
    "    for x in primaries\n",
    "    for y in energy_bins\n",
    "    for z in atms\n",
    "]\n",
    "\n",
    "# create the index by appending\n",
    "for index_name in indexes:\n",
    "    proton_index = pd.read_csv(folder_path + index_name, on_bad_lines=\"skip\")\n",
    "    photon_rec_index = pd.read_csv(\n",
    "        folder_path + index_name.replace(\"hadron\", \"photon\"), on_bad_lines=\"skip\"\n",
    "    )\n",
    "    index_ = pd.merge(\n",
    "        proton_index,\n",
    "        photon_rec_index,\n",
    "        on=[\"filename\", \"atm_model\", \"shower_id\", \"use_id\"],\n",
    "        how=\"left\",\n",
    "    )\n",
    "    index = pd.concat([index, index_], ignore_index=True)\n",
    "\n",
    "index = index.drop_duplicates()\n",
    "index = index.drop_duplicates(subset=[\"filename\"])\n",
    "# we won't train using iron\n",
    "index[\"mass_group\"] = index[\"filename\"].str.split(pat=\"_\", expand=True)[0]\n",
    "index = index[index[\"mass_group\"] != \"Iron\"]\n",
    "print(f\"Events before quality cuts: {len(index)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87593045-cbbb-4c54-bf4c-9ffd76e85622",
   "metadata": {},
   "outputs": [],
   "source": [
    "index.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05342499-ec0b-4e89-9a80-b5555c164eb0",
   "metadata": {},
   "source": [
    "### Quality Cuts and Binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c59273-303d-4264-a48f-e101b1c57b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = index.sample(frac=1)\n",
    "index.loc[index[\"filename\"].str.contains(\"Photon\"), \"isPhoton\"] = 1\n",
    "index.loc[index[\"filename\"].str.contains(\"Proton\"), \"isPhoton\"] = 0\n",
    "\n",
    "index[\"sin2zenith\"] = np.sin(index[\"zenithMC\"]) ** 2\n",
    "# photon efficiency from fit from simulations\n",
    "index[\"est_efficiency\"] = (\n",
    "    15.4074\n",
    "    + 17.4996 * (np.log10(index[\"energyMC\"]) - 17)\n",
    "    - 12.7485 * index[\"sin2zenith\"]\n",
    "    - 20.7650 * index[\"sin2zenith\"] ** 2\n",
    "    - 13.1239 * (np.log10(index[\"energyMC\"]) - 17) * index[\"sin2zenith\"]\n",
    ")\n",
    "index[\"est_efficiency\"] = expit(index[\"est_efficiency\"])\n",
    "\n",
    "feature_filters = {\n",
    "    \"zenithMC\": {\"filter_type\": \"range\", \"max_cut\": np.deg2rad(45)},\n",
    "    \"photon_energy\": {\"filter_type\": \"range\", \"min_cut\": 1},\n",
    "#    \"est_efficiency\": {\"filter_type\": \"range\", \"min_cut\": 0.9},\n",
    "    \"isT5\": {\"filter_type\": \"value\", \"value_to_keep\": 1}\n",
    "    #\"is5T5\": {\"filter_type\": \"value\", \"value_to_keep\": 1},\n",
    "    #\"is6T5\": {\"filter_type\": \"value\", \"value_to_keep\": 1},\n",
    "\n",
    "}\n",
    "index = filter_dataframe(index, feature_filters)\n",
    "\n",
    "index, e_bin_centers, e_bin_edges, e_labels = create_bins(\n",
    "    index,\n",
    "    lower_val=10**16.5,\n",
    "    upper_val=10**17.5,\n",
    "    num=6,\n",
    "    unbinned_col=\"energyMC\",\n",
    "    bin_column_name=\"e_bin\",\n",
    "    bin_width=\"equal_logarithmic\",\n",
    ")\n",
    "\n",
    "index, z_bin_centers, z_bin_edges, z_labels = create_bins(\n",
    "    index,\n",
    "    lower_val=0,\n",
    "    upper_val=np.sin(np.deg2rad(45)) ** 2,\n",
    "    num=4,\n",
    "    unbinned_col=\"sin2zenith\",\n",
    "    bin_column_name=\"z_bin\",\n",
    "    bin_width=\"equal\",\n",
    ")\n",
    "\n",
    "index = index.loc[~index[\"e_bin\"].isnull()]\n",
    "\n",
    "# problems in ADSTs\n",
    "exclude_list = [\n",
    "\"Photon_17.0_17.5_011102_11\",\n",
    "\"Photon_17.0_17.5_080595_20\"\n",
    "]\n",
    "index = index[~index['filename'].isin(exclude_list)]\n",
    "\n",
    "print(f\"Events after quality cuts: {len(index)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254cccb4-87f7-4281-9024-05fb739a2232",
   "metadata": {},
   "source": [
    "### Balanced Dataset Division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a54515-f7c1-4aef-bd22-ccafd3351f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_fatt_ph(sec, dsec):\n",
    "#     def func(x, p0, p1, p2, p3):\n",
    "#         return p0 * (1 + (x - p2) / p1)**(p1 / p3) * np.exp(-(x - p2) / p3)\n",
    "\n",
    "#     # Parameters and their errors\n",
    "#     popt = [3.88940e+01, 6.23117e-01, 1.00999e+00, 9.04938e-02]\n",
    "#     perr = [5.62431e-02, 5.26757e-02, 2.32738e-03, 4.79750e-03]\n",
    "\n",
    "#     # Evaluate the function\n",
    "#     f = func(sec, *popt)\n",
    "\n",
    "#     # Unpack parameters and their errors\n",
    "#     f0, f1, f2, f3 = popt\n",
    "#     df0, df1, df2, df3 = perr\n",
    "\n",
    "#     # Calculate the error\n",
    "#     factor = 1 + (sec - f2) / f1\n",
    "#     var0 = (f * df0 / f0)**2\n",
    "#     var1 = (f * (np.log(factor) / f3 - (sec - f2) / (f1 * f3 * factor)) * df1)**2\n",
    "#     var2 = (f * (f2 - sec) * df2 / (f3 * (f2 - sec - f1)))**2\n",
    "#     var3 = (f * (f1 * np.log(factor) - sec + f2) * df3 / f3**2)**2\n",
    "#     var4 = (-f * (sec - f2) * dsec / (f3 * (sec - f2 + f1)))**2\n",
    "#     df = np.sqrt(var0 + var1 + var2 + var3 + var4)\n",
    "\n",
    "#     return [f, df]\n",
    "\n",
    "# def get_norm_fatt_ph(sec, dsec):\n",
    "#     v_fatt_ph = get_fatt_ph(sec, dsec)\n",
    "#     secref = np.cos(30 * np.pi / 180)**-1\n",
    "#     norm = get_fatt_ph(secref, 0)[0]\n",
    "#     v = [v_fatt_ph[0] / norm, v_fatt_ph[1] / norm]\n",
    "#     return v\n",
    "\n",
    "# def get_fatt_pr(x, dx):\n",
    "#     def func(x, a, b, c):\n",
    "#         return 1 + a * x + b * x**2 + c * x**3\n",
    "\n",
    "#     # Parameters and their errors\n",
    "#     popt = [1.88357, -1.74331, -3.45984]\n",
    "#     perr = [2.81332e-03, 1.45271e-02, 5.38753e-02]\n",
    "\n",
    "#     # Evaluate the function\n",
    "#     f = func(x, *popt)\n",
    "\n",
    "#     # Unpack parameters and their errors\n",
    "#     f1, f2, f3 = popt\n",
    "#     df1, df2, df3 = perr\n",
    "\n",
    "#     # Calculate the error\n",
    "#     var1 = (x * df1)**2\n",
    "#     var2 = (x**2 * df2)**2\n",
    "#     var3 = (x**3 * df3)**2\n",
    "#     varx = ((f1 + 2 * f2 * x + 3 * f3 * x**2) * dx)**2\n",
    "#     df = np.sqrt(var1 + var2 + var3 + varx)\n",
    "\n",
    "#     return [f, df]\n",
    "\n",
    "# def get_photon_norm():\n",
    "#     secref = np.cos(30 * np.pi / 180)**-1\n",
    "#     photon_norm = get_fatt_ph(secref, 0)[0]\n",
    "#     return photon_norm\n",
    "\n",
    "# photon_norm = get_photon_norm()\n",
    "\n",
    "# x = np.cos(np.deg2rad(30))**2 - np.cos(np.deg2rad(30))**2\n",
    "# dx = 1\n",
    "# alpha = 1.15 * (1 - 0.192 * pow(pow(np.cos(np.deg2rad(30)), 2), 2.96))\n",
    "# eq_energy = pow(10,16) * pow((38.9545 / (get_fatt_pr(x, dx)[0]*photon_norm)), (1/alpha))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6b3780-b973-4152-855c-9307b2fc8ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the two categorical variables for stratified sampling\n",
    "index[\"categorical_balance\"] = (\n",
    "    index[\"isPhoton\"].astype(str)\n",
    "    + \"_\"\n",
    "    + index[\"e_bin\"].astype(str)\n",
    "    + \"_\"\n",
    "    + index[\"z_bin\"].astype(str)\n",
    ")\n",
    "\n",
    "random_seed = 42\n",
    "stratified_split = StratifiedShuffleSplit(\n",
    "    n_splits=1, test_size=0.25, random_state=random_seed\n",
    ")\n",
    "\n",
    "for dev_index_, test_index_ in stratified_split.split(\n",
    "    index, index[\"categorical_balance\"]\n",
    "):\n",
    "    # Original Training set\n",
    "    dev_index = index.iloc[dev_index_]\n",
    "\n",
    "    # Testing set\n",
    "    test_index = index.iloc[test_index_]\n",
    "\n",
    "# Further split the original training set into train and validation sets\n",
    "validation_size = 0.25  # Adjust as needed\n",
    "split = StratifiedShuffleSplit(\n",
    "    n_splits=1, test_size=validation_size, random_state=random_seed\n",
    ")\n",
    "\n",
    "for train_index_, validation_index_ in split.split(\n",
    "    dev_index, dev_index[\"categorical_balance\"]\n",
    "):\n",
    "    train_index = dev_index.iloc[train_index_]\n",
    "    validation_index = dev_index.iloc[validation_index_]\n",
    "\n",
    "# Print the size of each dataset\n",
    "print(\"Train dataset size:\", train_index.shape[0])\n",
    "print(\"Validation dataset size:\", validation_index.shape[0])\n",
    "print(\"Test dataset size:\", test_index.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba47953c-55f1-4086-a7a1-9a80b4af0194",
   "metadata": {},
   "source": [
    "### Generation of Normalization Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb598c7-7116-4e02-8222-b09ae9649e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = \"/sps/pauger/users/erodriguez/PhotonDiscrimination/JSONfiles/\"\n",
    "root_path = \"/sps/pauger/users/erodriguez/PhotonDiscrimination/root/\"\n",
    "\n",
    "test_run = True\n",
    "n_train_evts = 1000 if test_run else len(train_index)\n",
    "n_val_evts = 0 if test_run else len(validation_index)\n",
    "n_test_evts = 0 if test_run else len(test_index)\n",
    "\n",
    "# set paths according to index\n",
    "train_paths = list(train_index.iloc[:n_train_evts, 0].values)\n",
    "train_paths = list(map(lambda item: dir_path + item + \".json\", train_paths))\n",
    "val_paths = list(validation_index.iloc[:n_val_evts, 0].values)\n",
    "val_paths = list(map(lambda item: dir_path + item + \".json\", val_paths))\n",
    "test_paths = list(test_index.iloc[:n_test_evts, 0].values)\n",
    "test_paths = list(map(lambda item: dir_path + item + \".json\", test_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0337743-00a2-4ad9-89d5-ac9ee806ca95",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_already_computed = True\n",
    "if dict_already_computed:\n",
    "    normalization_dict = {\n",
    " 'WCD_signal': {'mean': 0.9242377699753578,\n",
    "                'method': 'standardization',\n",
    "                'std': 0.7037094813650729},\n",
    " 'deltaTimeHottest': {'mean': -47.27531568592806,\n",
    "                      'method': 'standardization',\n",
    "                      'std': 603.6062483849028},\n",
    " 'effective_area': {'max': 31.380000000000003,\n",
    "                    'method': 'min_max_scaling',\n",
    "                    'min': 0},\n",
    " 'pmt_number': {'max': 3, 'method': 'min_max_scaling', 'min': 1},\n",
    " 'rho_mu': {'mean': 0.21510971141596952,\n",
    "            'method': 'standardization',\n",
    "            'std': 0.9057438827119321},\n",
    " 'x': {'mean': -1.01887806305201,\n",
    "       'method': 'standardization',\n",
    "       'std': 364.5171135403138},\n",
    " 'y': {'mean': -0.06542848666299515,\n",
    "       'method': 'standardization',\n",
    "       'std': 356.8056580363697},\n",
    " 'z': {'mean': -0.16543275617686548,\n",
    "       'method': 'standardization',\n",
    "       'std': 6.410170534866934}}\n",
    "\n",
    "else:\n",
    "    # takes around 40 min\n",
    "    station_features = [\n",
    "        \"x\",\n",
    "        \"y\",\n",
    "        \"z\",\n",
    "        \"deltaTimeHottest\",\n",
    "        \"pmt_number\",\n",
    "        #\"WCD_signal\",\n",
    "        \"effective_area\",\n",
    "        \"rho_mu\",  # muon density will always go latest\n",
    "    ]\n",
    "\n",
    "    massive_array = get_station_features(train_paths, station_features)\n",
    "    mean_array = np.nanmean(massive_array, axis=0)\n",
    "    std_array = np.nanstd(massive_array, axis=0)\n",
    "\n",
    "    normalization_dict = {}\n",
    "    for idx, feature in enumerate(station_features):\n",
    "        normalization_dict[feature] = {}\n",
    "        normalization_dict[feature][\"method\"] = \"standardization\"\n",
    "        normalization_dict[feature][\"mean\"] = mean_array[idx]\n",
    "        normalization_dict[feature][\"std\"] = std_array[idx]\n",
    "\n",
    "    # overwrite some values that are better normalized as follows\n",
    "    normalization_dict[\"pmt_number\"] = {\n",
    "        \"method\": \"min_max_scaling\",\n",
    "        \"min\": 1,\n",
    "        \"max\": 3,\n",
    "    }\n",
    "    normalization_dict[\"effective_area\"] = {\n",
    "        \n",
    "        \"method\": \"min_max_scaling\",\n",
    "        \"min\": 0,\n",
    "        \"max\": 3 * 10.46,\n",
    "    }  # Kathy Turner will have more than 3 modules in data\n",
    "\n",
    "pprint(normalization_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede1630b-9167-4229-ab66-31afe529916b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_train_distributions = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa6208b-4e61-419e-bd2d-41cbdd97a879",
   "metadata": {},
   "outputs": [],
   "source": [
    "if plot_train_distributions:\n",
    "\n",
    "    histogram, bin_edges = np.histogram(massive_array[:,0], bins=100, density=True)\n",
    "\n",
    "    myStyle = MyStyle('1fig', markers=None)\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # plot the histogram\n",
    "    ax.bar(bin_edges[:-1], histogram, width=np.diff(bin_edges), edgecolor=\"red\", alpha=0.4, color=\"r\")\n",
    "    ax.set_ylabel(\"norm. counts\")\n",
    "\n",
    "    #feature lim and labels\n",
    "    feature_label = r\"$(x_{\\text{hottest}} - x) / \\text{m}$\"\n",
    "    #ax.set_ylim(-200, 350)\n",
    "    ax.set_xlabel(feature_label)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ce3001-5f8b-4a5c-9efa-986d78fe356b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if plot_train_distributions:\n",
    "\n",
    "    histogram, bin_edges = np.histogram(massive_array[:,1], bins=100, density=True)\n",
    "\n",
    "    myStyle = MyStyle('1fig', markers=None)\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # plot the histogram\n",
    "    ax.bar(bin_edges[:-1], histogram, width=np.diff(bin_edges), edgecolor=\"red\", alpha=0.4, color=\"r\")\n",
    "    ax.set_ylabel(\"norm. counts\")\n",
    "\n",
    "    #feature lim and labels\n",
    "    feature_label = r\"$(y_{\\text{hottest}} - y) / \\text{m}$\"\n",
    "    #ax.set_ylim(-200, 350)\n",
    "    ax.set_xlabel(feature_label)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e59efc-e473-428c-b5ba-8ec6347845cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if plot_train_distributions:\n",
    "\n",
    "    histogram, bin_edges = np.histogram(massive_array[:,2], bins=100, density=True)\n",
    "\n",
    "    myStyle = MyStyle('1fig', markers=None)\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # plot the histogram\n",
    "    ax.bar(bin_edges[:-1], histogram, width=np.diff(bin_edges), edgecolor=\"red\", alpha=0.4, color=\"r\")\n",
    "    ax.set_ylabel(\"norm. counts\")\n",
    "\n",
    "    #feature lim and labels\n",
    "    feature_label = r\"$(z_{\\text{hottest}} - z) / \\text{m}$\"\n",
    "    #ax.set_ylim(-200, 350)\n",
    "    ax.set_xlabel(feature_label)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19642d6-ba4a-4569-84d6-52a3395d38ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "if plot_train_distributions:\n",
    "\n",
    "    histogram, bin_edges = np.histogram(massive_array[:,3], bins=100, density=True)\n",
    "\n",
    "    myStyle = MyStyle('1fig', markers=None)\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # plot the histogram\n",
    "    ax.bar(bin_edges[:-1], histogram, width=np.diff(bin_edges), edgecolor=\"red\", alpha=0.4, color=\"r\")\n",
    "    ax.set_ylabel(\"norm. counts\")\n",
    "\n",
    "    #feature lim and labels\n",
    "    feature_label = r\"$(t_{\\text{hottest}} - t) / \\text{m}$\"\n",
    "    #ax.set_ylim(-200, 350)\n",
    "    ax.set_xlabel(feature_label)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bca4f01-9379-419d-9585-faca47a502eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if plot_train_distributions:\n",
    "\n",
    "    histogram, bin_edges = np.histogram(massive_array[:,4], bins=100, density=True)\n",
    "\n",
    "    myStyle = MyStyle('1fig', markers=None)\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # plot the histogram\n",
    "    ax.bar(bin_edges[:-1], histogram, width=np.diff(bin_edges), edgecolor=\"red\", alpha=0.4, color=\"r\")\n",
    "    ax.set_ylabel(\"norm. counts\")\n",
    "\n",
    "    #feature lim and labels\n",
    "    feature_label = r\"$N_{\\text{PMTs}}$\"\n",
    "    #ax.set_ylim(-200, 350)\n",
    "    ax.set_xlabel(feature_label)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e7b5d3-1052-492b-b3bc-9942ed45fc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "if plot_train_distributions:\n",
    "\n",
    "    histogram, bin_edges = np.histogram(massive_array[:,5], bins=100, density=True)\n",
    "\n",
    "    myStyle = MyStyle('1fig', markers=None)\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # plot the histogram\n",
    "    ax.bar(bin_edges[:-1], histogram, width=np.diff(bin_edges), edgecolor=\"red\", alpha=0.4, color=\"r\")\n",
    "    ax.set_ylabel(\"norm. counts\")\n",
    "\n",
    "    #feature lim and labels\n",
    "    feature_label = r\"$\\lg(S/\\text{VEM})$\"\n",
    "    #ax.set_ylim(-200, 350)\n",
    "    ax.set_xlabel(feature_label)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a1fb66-8ad9-4415-9af7-d9ac6ed75934",
   "metadata": {},
   "outputs": [],
   "source": [
    "if plot_train_distributions:    \n",
    "    \n",
    "    histogram, bin_edges = np.histogram(massive_array[:,6], bins=100, density=True)\n",
    "\n",
    "    myStyle = MyStyle('1fig', markers=None)\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # plot the histogram\n",
    "    ax.bar(bin_edges[:-1], histogram, width=np.diff(bin_edges), edgecolor=\"red\", alpha=0.4, color=\"r\")\n",
    "    ax.set_ylabel(\"norm. counts\")\n",
    "\n",
    "    #feature lim and labels\n",
    "    feature_label = r\"$\\text{Active Area}/m^2$\"\n",
    "    #ax.set_ylim(-200, 350)\n",
    "    ax.set_xlabel(feature_label)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df056a84-72d8-4015-b935-11ffc0f26503",
   "metadata": {},
   "outputs": [],
   "source": [
    "if plot_train_distributions:\n",
    "\n",
    "    histogram, bin_edges = np.histogram(massive_array[:,7], bins=10000, density=False)\n",
    "\n",
    "    myStyle = MyStyle('1fig', markers=None)\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # plot the histogram\n",
    "    ax.bar(bin_edges[:-1], histogram, width=np.diff(bin_edges), edgecolor=\"red\", alpha=0.4, color=\"r\")\n",
    "    ax.set_ylabel(\"norm. counts\")\n",
    "\n",
    "    #feature lim and labels\n",
    "    feature_label = r\"$\\rho_{\\mu}/\\text{m}^-2$\"\n",
    "    ax.set_xlim(-0.2, 0)\n",
    "    ax.set_xlabel(feature_label)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc7f41f-016b-48e4-8a89-287cef065802",
   "metadata": {},
   "source": [
    "### Datasets and Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89eb4133-c692-43da-82ad-0a4b6a5446dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dir_path = \"/sps/pauger/users/erodriguez/PhotonDiscrimination/JSONfiles/\"\n",
    "root_path = \"/sps/pauger/users/erodriguez/PhotonDiscrimination/root/\"\n",
    "\n",
    "# set paths according to index\n",
    "train_paths = list(train_index.iloc[:1000, 0].values)\n",
    "train_paths = list(map(lambda item: dir_path + item + \".json\", train_paths))\n",
    "\n",
    "train_PyG_ds = SD433UMDatasetPyG(\n",
    "    file_paths=train_paths,\n",
    "    norm_dict=normalization_dict,\n",
    "    root=root_path,\n",
    "    sample_PMTs=True,\n",
    "    sample_MD_mods=True,\n",
    "    n_time_bins=60,\n",
    "    neighbourhood_cut=450,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1af04fd-4b90-49e2-9bda-af3dd1230430",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graph(\n",
    "    graph,\n",
    "    feature_name,\n",
    "    norm_dict,\n",
    "    ax,\n",
    "    plot_edges=True,\n",
    "    node_color=\"cornflowerblue\",\n",
    "    size_amplifier=1,\n",
    "    x_pos_offset=0,\n",
    "    node_size_label=None,\n",
    "    plot_core = False,\n",
    "    linestyle=\"solid\",\n",
    "):\n",
    "\n",
    "    def retrieve_original_value(feature, method_info):\n",
    "        method = method_info[\"method\"]\n",
    "        if method == \"standardization\":\n",
    "            return feature * method_info[\"std\"] + method_info[\"mean\"]\n",
    "        elif method == \"min_max_scaling\":\n",
    "            return (\n",
    "                feature * (method_info[\"max\"] - method_info[\"min\"]) + method_info[\"min\"]\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported method: {method}\")\n",
    "\n",
    "    # Plot edges\n",
    "    if plot_edges:\n",
    "        for src, dst in graph[\"edge_index\"].t().tolist():\n",
    "            ax.plot(\n",
    "                [\n",
    "                    graph[\"pos\"][src, 0] + x_pos_offset,\n",
    "                    graph[\"pos\"][dst, 0] + x_pos_offset,\n",
    "                ],\n",
    "                [graph[\"pos\"][src, 1], graph[\"pos\"][dst, 1]],\n",
    "                color=\"gray\",\n",
    "                linestyle=linestyle,\n",
    "                alpha=0.33,\n",
    "            )\n",
    "\n",
    "    # Filter nodes based on the specified feature\n",
    "    feature_index = torch.tensor(\n",
    "        [i for i, feat in enumerate(graph[\"station_features\"]) if feat == feature_name]\n",
    "    )\n",
    "    node_sizes = graph[\"x\"][:, feature_index]\n",
    "    # Adjust node sizes based on method\n",
    "    node_sizes = retrieve_original_value(node_sizes, norm_dict[feature_name])\n",
    "    # Plot nodes above edges\n",
    "    ax.scatter(\n",
    "        graph[\"pos\"][:, 0] + x_pos_offset,\n",
    "        graph[\"pos\"][:, 1],\n",
    "        s=size_amplifier * node_sizes,\n",
    "        color=node_color,\n",
    "        label=node_size_label,\n",
    "        zorder=2,\n",
    "    )\n",
    "    \n",
    "    if plot_core:\n",
    "        ax.scatter(\n",
    "        graph[\"core\"][0],\n",
    "        graph[\"core\"][1], marker='x', color=\"green\", label=\"MC core\")\n",
    "        \n",
    "    delays = retrieve_original_value(graph.x[:,3], norm_dict[\"deltaTimeHottest\"])\n",
    "    # Add insets for node traces and other stuff\n",
    "    for i, (x, y) in enumerate(graph[\"pos\"]):\n",
    "        ax.text(\n",
    "            x.item() - 70,\n",
    "            y.item() - 60,\n",
    "            graph.station_list[i],\n",
    "            transform=ax.transData,\n",
    "            fontsize=14,\n",
    "        )\n",
    "        ax.text(\n",
    "            x.item() - 70,\n",
    "            y.item() - 120,\n",
    "            f\"$\\Delta t_{{ \\text{{hottest}} }}=$ {round(delays[i].item(), 0)} ns\",\n",
    "            transform=ax.transData,\n",
    "            fontsize=14,\n",
    "        )\n",
    "        inset_ax = ax.inset_axes(\n",
    "            [x.item() - 100, y.item() + 25, 200, 100], transform=ax.transData\n",
    "        )\n",
    "        inset_ax.plot(graph.x_traces[i, :], color=\"black\")\n",
    "        inset_ax.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be9a752-3091-49b9-acde-7aae6d1c3fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graph(\n",
    "    graph,\n",
    "    feature_name,\n",
    "    norm_dict,\n",
    "    ax,\n",
    "    plot_edges=True,\n",
    "    node_color=\"cornflowerblue\",\n",
    "    size_amplifier=1,\n",
    "    x_pos_offset=0,\n",
    "    node_size_label=None,\n",
    "    plot_core=False,\n",
    "    edge_color=\"grey\",\n",
    "    linestyle=\"solid\",\n",
    "):\n",
    "\n",
    "    def retrieve_original_value(feature, method_info):\n",
    "        method = method_info[\"method\"]\n",
    "        if method == \"standardization\":\n",
    "            return feature * method_info[\"std\"] + method_info[\"mean\"]\n",
    "        elif method == \"min_max_scaling\":\n",
    "            return (\n",
    "                feature * (method_info[\"max\"] - method_info[\"min\"]) + method_info[\"min\"]\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported method: {method}\")\n",
    "\n",
    "    # Plot edges\n",
    "    if plot_edges:\n",
    "        for src, dst in graph[\"edge_index\"].t().tolist():\n",
    "            ax.plot(\n",
    "                [\n",
    "                    graph[\"pos\"][src, 0] + x_pos_offset,\n",
    "                    graph[\"pos\"][dst, 0] + x_pos_offset,\n",
    "                ],\n",
    "                [graph[\"pos\"][src, 1], graph[\"pos\"][dst, 1]],\n",
    "                color=edge_color,\n",
    "                linestyle=linestyle,\n",
    "                alpha=0.33,\n",
    "            )\n",
    "\n",
    "    # Filter nodes based on the specified feature\n",
    "    feature_index = torch.tensor(\n",
    "        [i for i, feat in enumerate(graph[\"station_features\"]) if feat == feature_name]\n",
    "    )\n",
    "    node_sizes = graph[\"x\"][:, feature_index]\n",
    "    # Adjust node sizes based on method\n",
    "    node_sizes = retrieve_original_value(node_sizes, norm_dict[feature_name])\n",
    "    # Plot nodes above edges\n",
    "    ax.scatter(\n",
    "        graph[\"pos\"][:, 0] + x_pos_offset,\n",
    "        graph[\"pos\"][:, 1],\n",
    "        s=size_amplifier * node_sizes,\n",
    "        color=node_color,\n",
    "        label=node_size_label,\n",
    "        zorder=2,\n",
    "    )\n",
    "    \n",
    "    if plot_core:\n",
    "        ax.scatter(\n",
    "        graph[\"core\"][0],\n",
    "        graph[\"core\"][1], marker='x', color=\"green\", label=\"MC core\")\n",
    "        \n",
    "    delays = retrieve_original_value(graph.x[:,3], norm_dict[\"deltaTimeHottest\"])\n",
    "    # Add insets for node traces and other stuff\n",
    "    for i, (x, y) in enumerate(graph[\"pos\"]):\n",
    "        ax.text(\n",
    "            x.item() - 70,\n",
    "            y.item() - 60,\n",
    "            graph.station_list[i],\n",
    "            transform=ax.transData,\n",
    "            fontsize=14,\n",
    "        )\n",
    "        ax.text(\n",
    "            x.item() - 110,\n",
    "            y.item() - 120,\n",
    "            f\"$\\Delta t_{{ \\\\text{{hottest}} }}=$ {round(delays[i].item(), 0)} ns\",\n",
    "            transform=ax.transData,\n",
    "            fontsize=14,\n",
    "        )\n",
    "        inset_ax = ax.inset_axes(\n",
    "            [x.item() - 100, y.item() + 25, 200, 100], transform=ax.transData\n",
    "        )\n",
    "        inset_ax.plot(graph.x_traces[i, :], color=\"black\")\n",
    "        inset_ax.axis(\"off\")\n",
    "        \n",
    "def plot_simple_graph(graph, ax, kw_args_nodes, kw_args_edges, kw_args_traces, plot_edges=True, plot_traces=True, ):\n",
    "    \n",
    "    # plotting edges\n",
    "    if plot_edges:\n",
    "        \n",
    "        for src, dst in graph[\"edge_index\"].t().tolist():\n",
    "            ax.plot(\n",
    "                [\n",
    "                    graph[\"pos\"][src, 0],\n",
    "                    graph[\"pos\"][dst, 0],\n",
    "                ],\n",
    "                [graph[\"pos\"][src, 1], graph[\"pos\"][dst, 1]],\n",
    "                **kw_args_edges\n",
    "            )\n",
    "            \n",
    "    # plotting nodes\n",
    "    for i, (x, y) in enumerate(graph[\"pos\"]):\n",
    "        \n",
    "        plt.scatter(x, y, **kw_args_nodes)\n",
    "        \n",
    "        if plot_traces:\n",
    "            inset_ax = ax.inset_axes(\n",
    "            [x.item() - 100, y.item() + 25, 200, 100], transform=ax.transData\n",
    "            )\n",
    "            inset_ax.plot(graph.x_traces[i, :], color=\"black\", **kw_args_traces)\n",
    "            inset_ax.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bad827-b71d-4280-9ba4-a80b5a3c3c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_PyG_ds = SD433UMDatasetPyG(\n",
    "    file_paths=train_paths,\n",
    "    norm_dict=normalization_dict,\n",
    "    root=root_path,\n",
    "    sample_PMTs=True,\n",
    "    sample_MD_mods=True,\n",
    "    n_time_bins=60,\n",
    "    neighbourhood_cut=450,\n",
    "    \n",
    ")\n",
    "\n",
    "graph = train_PyG_ds[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca687092-948f-4530-a8ca-3b6298391658",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d29562-0390-461c-a72d-8482bea0a30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61acdb10-439f-4bf1-89e6-ed7f7a52494a",
   "metadata": {},
   "outputs": [],
   "source": [
    "myStyle = MyStyle(\"1fig\", markers=None)\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "color=\"black\"\n",
    "kw_args_nodes = {\"color\":color}\n",
    "kw_args_edges = {\"color\":color}\n",
    "kw_args_traces = {}\n",
    "\n",
    "plot_simple_graph(graph, ax=ax, kw_args_nodes=kw_args_nodes, kw_args_edges=kw_args_edges, kw_args_traces=kw_args_traces)\n",
    "ax.axis(\"off\")\n",
    "plt.axis('equal')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b9d804-a9d5-4c89-9c53-e9e9ecb3f931",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_masking_transform =  MaskNode(max_nodes2prune=2)\n",
    "masked_graph1 = node_masking_transform(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebf8962-35fe-49ed-9ae3-96206e8320ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "myStyle = MyStyle(\"1fig\", markers=None)\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "color=\"blue\"\n",
    "kw_args_nodes = {\"color\":color}\n",
    "kw_args_edges = {\"color\":color}\n",
    "kw_args_traces = {}\n",
    "\n",
    "plot_simple_graph(masked_graph1, ax=ax, kw_args_nodes=kw_args_nodes, kw_args_edges=kw_args_edges, kw_args_traces=kw_args_traces)\n",
    "ax.axis(\"off\")\n",
    "plt.axis('equal')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1994d6e-cd77-4c16-abc5-4a07bb327d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_masking_transform =  MaskNode(max_nodes2prune=2)\n",
    "masked_graph2 = node_masking_transform(masked_graph1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3917140a-f1c7-4f72-bad9-9f2dd3c8200d",
   "metadata": {},
   "outputs": [],
   "source": [
    "myStyle = MyStyle(\"1fig\", markers=None)\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "color=\"red\"\n",
    "kw_args_nodes = {\"color\":color}\n",
    "kw_args_edges = {\"color\":color}\n",
    "kw_args_traces = {}\n",
    "\n",
    "plot_simple_graph(masked_graph2, ax=ax, kw_args_nodes=kw_args_nodes, kw_args_edges=kw_args_edges, kw_args_traces=kw_args_traces)\n",
    "ax.axis(\"off\")\n",
    "plt.axis('equal')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3fd5130-d264-4321-b8be-1e7982952450",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc2e3af-2fbc-4a44-8b7b-678c80a40f0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04deba7b-136f-41e4-b55b-06492fb7148a",
   "metadata": {},
   "outputs": [],
   "source": [
    "myStyle = MyStyle(\"1fig\", markers=None)\n",
    "fig, ax = plt.subplots()\n",
    "#plot_graph(\n",
    "#    graph,\n",
    "#    \"WCD_signal\",\n",
    "#    normalization_dict,\n",
    "#    ax,\n",
    "#    node_size_label=r\"$S_{WCD}$\",\n",
    "#    size_amplifier=1.5,\n",
    "#)\n",
    "plot_graph(\n",
    "    graph,\n",
    "    \"rho_mu\",\n",
    "    normalization_dict,\n",
    "    ax,\n",
    "    plot_edges=True,\n",
    "    node_color=\"blue\",\n",
    "    size_amplifier=10,\n",
    "    node_size_label=r\"$\\rho_{\\mu}$\",\n",
    "    linestyle=None,\n",
    "    plot_core=False,\n",
    "    edge_color=\"blue\",\n",
    ")\n",
    "ax.set_aspect(\"equal\", adjustable=\"box\")\n",
    "ax.axis(\"off\")\n",
    "ax.text(x=0.01, y=0.99, s=r\"$\\gamma$\" if graph.y == 1 else r\"$p$\",  ha='left', va='top', transform=ax.transAxes)\n",
    "#ax.legend(loc=\"upper right\", fontsize=14)\n",
    "# plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5790fd-aa18-46f9-ac6d-b54e7a29264f",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_masking_transform =  MaskNode(max_nodes2prune=2)\n",
    "masked_node = node_masking_transform(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd803fc-3acb-41d9-8753-82a882ff7a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "myStyle = MyStyle(\"1fig\", markers=None)\n",
    "fig, ax = plt.subplots()\n",
    "plot_graph(\n",
    "    masked_node,\n",
    "    \"WCD_signal\",\n",
    "    normalization_dict,\n",
    "    ax,\n",
    "    node_size_label=r\"$S_{WCD}$\",\n",
    "    size_amplifier=1,\n",
    ")\n",
    "plot_graph(\n",
    "    masked_node,\n",
    "    \"rho_mu\",\n",
    "    normalization_dict,\n",
    "    ax,\n",
    "    plot_edges=False,\n",
    "    node_color=\"red\",\n",
    "    size_amplifier=1.5,\n",
    "    node_size_label=r\"$\\rho_{\\mu}$\",\n",
    "    linestyle=None,\n",
    "    plot_core=True,\n",
    ")\n",
    "ax.set_aspect(\"equal\", adjustable=\"box\")\n",
    "ax.axis(\"off\")\n",
    "ax.text(x=0.01, y=0.99, s=r\"$\\gamma$\" if graph.y == 1 else r\"$p$\",  ha='left', va='top', transform=ax.transAxes)\n",
    "ax.legend(loc=\"upper right\", fontsize=14)\n",
    "# plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64766fa8-61f2-447d-9f57-666bd7a97843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# myStyle = MyStyle(\"1fig\", markers=None)\n",
    "# fig, ax = plt.subplots()\n",
    "# station_features = [\n",
    "#     \"$x$\",\n",
    "#     \"$y$\",\n",
    "#     \"$z$\",\n",
    "#     r\"$\\Delta t_{{\\text{{hottest}}}}$\",\n",
    "#     r\"$N_{\\text{PMT}}$\",\n",
    "#     r\"$S_{\\text{WCD}}$\",\n",
    "#     r\"$A_{\\mu}$\",\n",
    "#     r\"$\\rho_{\\mu}$\",\n",
    "# ]\n",
    "# # Create the table with adjusted position, size, and font size\n",
    "# table_x = ax.table(\n",
    "#     cellText=graph.x.numpy(),\n",
    "#     colWidths=[0.3] * len(graph.station_features),\n",
    "#     rowLabels=graph.station_list,\n",
    "#     colLabels=station_features,\n",
    "#     loc=\"center\",\n",
    "#     bbox=[0, 0, 1, 1],\n",
    "#     cellLoc=\"center\",\n",
    "#     fontsize=24,\n",
    "# )  # Adjust fontsize as needed\n",
    "# ax.axis(\"off\")\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01499a4-1379-440b-84ea-bb788d37b07c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# myStyle = MyStyle(\"1fig\", markers=None)\n",
    "# fig, ax = plt.subplots()\n",
    "\n",
    "# adj_matrix = (\n",
    "#     torch_geometric.utils.to_torch_coo_tensor(graph.edge_index).to_dense().numpy()\n",
    "# )\n",
    "# # Create the table\n",
    "# table_edges = ax.table(\n",
    "#     cellText=adj_matrix,\n",
    "#     colWidths=[0.1] * len(graph.station_list),\n",
    "#     rowLabels=graph.station_list,\n",
    "#     colLabels=graph.station_list,\n",
    "#     loc=\"center\",\n",
    "#     bbox=[0, 0, 1, 1],\n",
    "#     cellLoc=\"center\",\n",
    "#     fontsize=18,\n",
    "# )\n",
    "\n",
    "# # Iterate over table cells and shade non-zero cells with light grey\n",
    "# for i in range(len(adj_matrix)):\n",
    "#     for j in range(len(adj_matrix[i])):\n",
    "#         if adj_matrix[i][j] != 0:\n",
    "#             table_edges[(i + 1, j)].set_facecolor(\"grey\")  # Light grey color\n",
    "\n",
    "# # Turn off axis and adjust layout\n",
    "# ax.axis(\"off\")\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad484370-9ec5-4979-9c5b-f8a2e421ffac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# myStyle = MyStyle(\"1fig\", markers=None)\n",
    "# fig, ax = plt.subplots()\n",
    "# trimmed_traces = graph.x_traces[:, :25].numpy()\n",
    "# table_edges = ax.table(\n",
    "#     cellText=trimmed_traces,\n",
    "#     colWidths=[0.1] * trimmed_traces.shape[1],\n",
    "#     rowLabels=graph.station_list,\n",
    "#     loc=\"center\",\n",
    "#     bbox=[0, 0, 1, 1],\n",
    "#     cellLoc=\"center\",\n",
    "#     fontsize=18,\n",
    "# )  # Adjust fontsize as needed\n",
    "# ax.axis(\"off\")\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e395247-81d9-4674-bf69-9994b13d972b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dir_path = \"/sps/pauger/users/erodriguez/PhotonDiscrimination/JSONfiles/\"\n",
    "root_path = \"/sps/pauger/users/erodriguez/PhotonDiscrimination/root/\"\n",
    "\n",
    "# set paths according to index\n",
    "train_paths = list(train_index.iloc[:, 0].values)\n",
    "train_paths = list(map(lambda item: dir_path + item + \".json\", train_paths))\n",
    "val_paths = list(validation_index.iloc[:, 0].values)\n",
    "val_paths = list(map(lambda item: dir_path + item + \".json\", val_paths))\n",
    "test_paths = list(test_index.iloc[:, 0].values)\n",
    "test_paths = list(map(lambda item: dir_path + item + \".json\", test_paths))\n",
    "\n",
    "# generate Datasets\n",
    "train_PyG_ds = SD433UMDatasetPyG(\n",
    "    file_paths=train_paths,\n",
    "    norm_dict=normalization_dict,\n",
    "    root=root_path,\n",
    "    sample_PMTs=True,\n",
    "    sample_MD_mods=True,\n",
    ")\n",
    "val_PyG_ds = SD433UMDatasetPyG(\n",
    "    file_paths=val_paths,\n",
    "    norm_dict=normalization_dict,\n",
    "    root=root_path,\n",
    "    sample_PMTs=True,\n",
    "    sample_MD_mods=True,\n",
    ")\n",
    "test_PyG_ds = SD433UMDatasetPyG(\n",
    "    file_paths=test_paths,\n",
    "    norm_dict=normalization_dict,\n",
    "    root=root_path,\n",
    "    sample_PMTs=True,\n",
    "    sample_MD_mods=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d084f0-37df-4f8c-8cb7-9d66a7227c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate Loaders\n",
    "train_loader = DataLoader(train_PyG_ds, batch_size=32, shuffle=True, num_workers=8)\n",
    "val_loader = DataLoader(val_PyG_ds, batch_size=32, num_workers=8)\n",
    "test_loader = DataLoader(test_PyG_ds, batch_size=32, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358ec3f4-97d0-4d27-a86e-97996df843d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_idx, data in enumerate(\n",
    "    tqdm(train_loader, desc=\"Batch\", position=0, leave=True)\n",
    "):\n",
    "    if torch.isnan(data.x).any():\n",
    "        print(\"Batch id: \",batch_idx)\n",
    "        print(\"Nan on Features\")\n",
    "        print(data.x)\n",
    "        saved_problem = data.x\n",
    "        nan_indices = torch.nonzero(torch.isnan(saved_problem)).flatten()\n",
    "        print(\"Indices of NaNs:\", nan_indices.tolist())\n",
    "    if torch.isnan(data.x_traces).any():\n",
    "        print(\"Batch id: \",batch_idx)\n",
    "        print(\"Nan on Traces\")\n",
    "        saved_problem = data.x_traces\n",
    "        nan_indices = torch.nonzero(torch.isnan(saved_problem)).flatten()\n",
    "        print(\"Indices of NaNs:\", nan_indices.tolist())\n",
    "        print(\"Features\")\n",
    "        print(data.x[nan_indices[0], :])\n",
    "        print(\"Norm. Traces after Sampling\")\n",
    "        print(data.x_traces[nan_indices[0],:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade90a5a-5b4e-4290-b518-903c58687e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_idx, data in enumerate(\n",
    "    tqdm(val_loader, desc=\"Batch\", position=0, leave=True)\n",
    "):\n",
    "    if torch.isnan(data.x).any():\n",
    "        print(\"Batch id: \",batch_idx)\n",
    "        print(\"Nan on Features\")\n",
    "        print(data.x)\n",
    "        saved_problem = data.x\n",
    "        nan_indices = torch.nonzero(torch.isnan(saved_problem)).flatten()\n",
    "        print(\"Indices of NaNs:\", nan_indices.tolist())\n",
    "    if torch.isnan(data.x_traces).any():\n",
    "        print(\"Batch id: \",batch_idx)\n",
    "        print(\"Nan on Traces\")\n",
    "        saved_problem = data.x_traces\n",
    "        nan_indices = torch.nonzero(torch.isnan(saved_problem)).flatten()\n",
    "        print(\"Indices of NaNs:\", nan_indices.tolist())\n",
    "        print(\"Features\")\n",
    "        print(data.x[nan_indices[0], :])\n",
    "        print(\"Norm. Traces after Sampling\")\n",
    "        print(data.x_traces[nan_indices[0],:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135b28a5-4ea2-4e6b-8b8a-f988bb35910c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_idx, data in enumerate(\n",
    "    tqdm(test_loader, desc=\"Batch\", position=0, leave=True)\n",
    "):\n",
    "    if torch.isnan(data.x).any():\n",
    "        print(\"Batch id: \",batch_idx)\n",
    "        print(\"Nan on Features\")\n",
    "        print(data.x)\n",
    "        saved_problem = data.x\n",
    "        nan_indices = torch.nonzero(torch.isnan(saved_problem)).flatten()\n",
    "        print(\"Indices of NaNs:\", nan_indices.tolist())\n",
    "    if torch.isnan(data.x_traces).any():\n",
    "        print(\"Batch id: \",batch_idx)\n",
    "        print(\"Nan on Traces\")\n",
    "        saved_problem = data.x_traces\n",
    "        nan_indices = torch.nonzero(torch.isnan(saved_problem)).flatten()\n",
    "        print(\"Indices of NaNs:\", nan_indices.tolist())\n",
    "        print(\"Features\")\n",
    "        print(data.x[nan_indices[0], :])\n",
    "        print(\"Norm. Traces after Sampling\")\n",
    "        print(data.x_traces[nan_indices[0],:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".phd-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
